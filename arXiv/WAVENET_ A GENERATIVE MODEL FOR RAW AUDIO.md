# WAVENET: A GENERATIVE MODEL FOR RAW AUDIO
###### tags: `survey`

## 1. 概要
CNNを用いた，時間波形に対する確率的生成モデルWaveNetに関する研究．画像・テキスト生成に用いられてきたPixelCNN，PixelRNNの枠組みを適用し，帯域の広い音声波形の生成を行う．

ちなみにWavwNetの計算時間，品質などを確認するため，追試を行なってみた([WaveNet_vocoder_chainer](https://github.com/Takaaki-Saeki/WaveNet_vocoder_chainer))．

## 2. 先行研究と比較して何がすごいのか
1. 提案法のWaveNetにより，Text-to-Speechの分野ではこれまで報告されなかったほどの自然な音声の生成を行えることを主観評価により示した．
2. 長期にわたる時間依存性を捉えるため，広範囲の受容野を表すdilated causal convolutionに基づく新たなアーキテクチャを設計した．
3. 話者性に条件付けされている場合，．単一のモデルでも異なった音声を生成できることを示した．
4. 同様のアーキテクチャを小規模な音声認識データセットに対して適用した場合にも良好な結果を示し，また音楽などといった音響信号生成に適用することも十分可能である．

## 3. 手法のキモ
WaveNetでは次の値を予測するときに，回帰問題として解くのではなく，他クラス分類問題として解くが，そのまま扱うのでは-32767~32767の値を取り，このまま処理するのは現実的ではない．そこでmu-law量子化によって256段階に圧縮する．

WaveNetは自己回帰モデルであり，過去のある時刻までの範囲の全ての信号を入力として受け取り，次の時刻の信号を予測する．論文中では，「過去のデータをどれだけの範囲見るか」ということを受容野と呼んでいる．WaveNetでは，CNNを用いて時系列を考慮した特徴量を得る．
下のように，フィルタサイズ2でたたみ込んで行くと，受容野の全てを考慮するためには膨大な隠れ層が必要になってしまう．
![](https://i.imgur.com/099jKVw.png)
この問題を解決するために，Dilated Convolutionを用いる．
このように，層を経るにつれて畳み込みの間隔を広くしていくことにより，はるかに少ない層の数で，受容野の全てをカバーできる．
![](https://i.imgur.com/huGBxk2.png)
先ほど述べたditated convolutionの何層かをまとめて一つのResidual Blockと見なし，これをさらに何層にも重ねて深いResidual Networkを作る．
![](https://i.imgur.com/gT9LIzF.png)


## 4. 実験・検証方法
多話者の音声生成，Text-to-Speech，音楽生成，音声認識などで実験的検証を行なっている．

## 5. 議論
全部書くと長いので，特に興味深かった，他話者の音声生成のみについて書く．
他話者の音声生成の実験では，109人の英語話者のデータセットを用い，話者でのみ条件付けを行うものとした．
textで条件付けを行なっていないため，実際には存在しないが，人間の言葉のようであり，あり得そうなイントネーションを持つような単語が生成された．この場合は2，3個前の音素しか見ていない．
一つのWaveNetが，話者を表すone hotベクトルだけで十分に発話をモデル化することができた．さらに，これに話者を追加しても良いvalidationスコアが出たので，wavenetの持つ洗剤表現が話者間で共有されていることを表す．またWaveNetが音声以外の特徴も捉えていることが明らかになった．

## 6. 次に読むべき論文
- Aaron van den Oord et al., "Pixel Recurrent Neural Networks"
- Aaron van den Oord et al., "Conditional Image Generation with PixelCNN Decoders"