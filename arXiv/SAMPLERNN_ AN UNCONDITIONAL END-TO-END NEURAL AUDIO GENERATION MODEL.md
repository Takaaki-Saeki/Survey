# SAMPLERNN: AN UNCONDITIONAL END-TO-END NEURAL AUDIO GENERATION MODEL
###### tags: `survey`

## 1. 概要
音声や音楽信号の生成に関する研究．この論文で提案されているSampleRNNでは，RNNを階層的に配置し，上の階層ほど長い時間依存を捉えるようにしている．本当はICLR2017だが，arXivも出ていたのでこちらに入れさせてもらった．

## 2. 先行研究と比較して何がすごいのか
異なる時間スケールを捉えるRNNを階層的に配置(上位のRNNほど時間スケールが大きくなる)し，長期の依存関係を捉えるだけでなく，それぞれのRNNの系列長は短くなるため学習時のメモリ効率が良い．

## 3. 手法のキモ
![](https://i.imgur.com/38uU2S6.png)
SampleRNNでは，図のようにRNNを階層的に配置し，上位のものほど長い時間スケールを扱う(上位のものほど時間分解能は悪くなる)．

図のTier2,3における機構について考える．時間tでのメモリセルの値を$h_{t}$とすると，これは時間t-1でのメモリセルでの値とinputとの線型結合(Tier2)または単にinput(Tier3)によって与えられる．
![](https://i.imgur.com/nSWSB3o.png)

それぞれの階層のRNNは異なる時間分解能で動作しているため，それぞれのベクトル$c$を$r^{(k)}$の系列にアップサンプリングする必要がある．ここで，上図ではいずれの階層においても$r=4$とした場合を想定している．

Tier1では，$x_{i+1}$以降の分布を出力する．これは，前のサンプルとベクトル$c_{i}^{k=2}$によって条件づけされており，MLPによってモデル化される．これは下式のように表される．
![](https://i.imgur.com/dPhMPYD.png)

ここで，$e_{i}$はembedding layerを通過した後の$x_{i}$を表している．
WaveNetなどと同様に，音響信号を量子化し，条件つき分布をモデル化するのにガウス分布や混合ガウス分布ではなく多項分布を用いる事で結果が良くなったことから，Softmax関数を用いた．

## 4. 実験・検証方法
Blizzard，Onomatopoeia，Musicの3つのデータセットを用いて評価実験を行なっている．
また，WaveNetの再実装も行い，比較対象としている．

## 5. 議論
Bllizard datasetでの主観評価の結果では，3-tiersのsampleRNNが圧倒的に優れた結果を示している．
またmusic datasetでは，比較的バラバラな結果となった．

## 6. 次に読むべき論文
- Pixel Recurrent Neural Networks